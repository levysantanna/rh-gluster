---

# Upgrade all packages
upgrade_packages: True

###############################################
# Network

# Used to bind services
mgmt_interface: eth0

internal_ip: "{{ hostvars[inventory_hostname][ 'ansible_' + mgmt_interface ].ipv4.address }}"

timezone: "America/Sao_Paulo"

dns_domain: example.com.br

# DNS Name searchs
dns_searchs:
  - example.com.br

# Name servers
dns_nameservers:
  - 8.8.8.8
  - 4.4.4.4

# Reset network configuration
network_reset: False

#Set true to disable firewalld
disable_firewalld: True

network_modules:
    - nf-conntrack
    - nf_conntrack_ipv4
    - nf_conntrack_ipv6
    - nf_conntrack_pptp
    - ip_conntrack_ftp
    - ip_gre
    - ip_nat_ftp
    - nf_conntrack_proto_gre
    - nf_nat_proto_gre
    - vhost_net

network_os_tuning_params:
  - { name: net.netfilter.nf_conntrack_tcp_timeout_close_wait, value: 30 }
  - { name: net.netfilter.nf_conntrack_tcp_timeout_fin_wait, value: 60 }
  - { name: net.netfilter.nf_conntrack_max, value: 524288 }
  - { name: net.bridge.bridge-nf-call-ip6tables, value: 1 }
  - { name: net.bridge.bridge-nf-call-iptables, value: 1 }
  - { name: net.bridge.bridge-nf-call-arptables, value: 1 }
  - { name: net.ipv4.conf.all.rp_filter, value: 0 }
  - { name: net.ipv4.conf.default.rp_filter, value: 0 }
  - { name: kernel.pid_max, value: 4194303 }
  - { name: fs.file-max, value: 26234859 }
  - { name: vm.zone_reclaim_mode, value: 0 }
  - { name: vm.vfs_cache_pressure, value: 50 }
  - { name: vm.min_free_kbytes, value: "{{ vm_min_free_kbytes }}" }
  - { name: net.core.rmem_max, value: 56623104 }
  - { name: net.core.wmem_max, value: 56623104 }
  - { name: net.core.rmem_default, value: 56623104 }
  - { name: net.core.optmem_max, value: 40960 }
  - { name: net.ipv4.tcp_rmem, value: 4096 87380 56623104 }
  - { name: net.core.wmem_default, value: 56623104 }
  - { name: net.ipv4.tcp_wmem, value: 4096 65536 56623104 }
  - { name: net.core.somaxconn, value: 1024 }
  - { name: net.core.netdev_max_backlog, value: 50000 }
  - { name: net.ipv4.tcp_max_syn_backlog, value: 30000 }
  - { name: net.ipv4.tcp_max_tw_buckets, value: 2000000 }
  - { name: net.ipv4.tcp_tw_recycle, value: 1 }
  - { name: net.ipv4.tcp_tw_reuse, value: 1 }
  - { name: net.ipv4.tcp_slow_start_after_idle, value: 0 }
  - { name: net.ipv4.udp_rmem_min, value: 8192 }
  - { name: net.ipv4.tcp_fin_timeout, value: 10 }
  - { name: net.ipv4.udp_wmem_min, value: 8192 }
  - { name: net.ipv4.conf.all.send_redirects, value: 0 }
  - { name: net.ipv4.conf.all.accept_redirects, value: 0 }
  - { name: net.ipv4.conf.all.accept_source_route, value: 0 }

network_packages:
  - libselinux-python
  - bridge-utils
  - iputils
  - tcpdump
  - nmap
  - telnet

################################################
## Red Hat Subscribe

# Use red hat subscribe
use_rhel: false

# RHN Username and password
rhel_subscription_user: username_rhn
rhel_subscription_pass: password_rhn

# Attach to pool_id
rhel_pool_id: redhat_pool_id

# Register repos
enable_repos: True
rhel_repos:
  - rhel-7-server-rpms
  - rhel-7-server-extras-rpms
  - rhel-7-server-optional-rpms
  - rh-gluster-3-for-rhel-7-server-rpms
  - rh-gluster-3-for-rhel-7-server-files
  - rh-gluster-3-nfs-for-rhel-7-server-rpms
  - rh-gluster-3-samba-for-rhel-7-server-rpms
  - rh-gluster-3-client-for-rhel-7-server-rpms

################################################
## Gluster LVM
reset_lvm: False
gluster_group_name: gluster
glusterfs_server_group: gluster
glusterfs_arbiter_group: gluster_arbiter

glusterfs_install_server: True
glusterfs_install_client: False
gluster_members:
  - nas-nfs02

# For JBOD, use an alignment value of 256K.
# In case of hardware RAID, the alignment_value should be obtained by multiplying the RAID stripe unit size with
# the number of data disks. If 12 disks are used in a RAID 6 configuration, the number of data disks is 10;
# on the other hand, if 12 disks are used in a RAID 10 configuration, the number of data disks is 6.
# For example:
# RAID 6 storage with 12 disks and a stripe unit size of 128KiB:
# RAID 10 storage with 12 disks and a stripe unit size of 256KiB:
# number_of_disk * strip_size
# In order to ensure that logical volumes created in the volume group are aligned with the underlying hardware RAID.

pv_disks:
  - vg_name: vgGluster01
    thin_name: tp1
    disk: /dev/vdb
    pv_dataalignment: 2560
    vg_extentsize: 256
    lv_chunk: 2560
    lv_metadatasize: 16G
#  - vg_name: vg-gluster01
#    thin_name: tp2
#    disk: /dev/vdc
#    pv_dataalignment: 2560
#    vg_extentsize: 256
#    lv_chunk: 2560
#    lv_metadatasize: 16G

gluster_bricks:
  - brick_name: storage
    virtualsize: 100G
    vg_name: vgGluster01
    thin_name: tp1

# TODO: Create method to get bricks mount dynamic
glusterfs_volumes:
  - name: volume1
    owner: root
    group: root
    replicas: 2
    force: True
    brick:
      - "{{ mount_point }}storage"
    options:
      - nfs.acl: on
      - nfs.export-volumes: on
      - nfs.disable: off

use_xfs: True
mkfs_options_xfs: -f -i size=512 -n size=8192 -d su=256k,sw=1
mount_options_xfs: nobarrier,inode64,noatime,nodiratime
mount_point: /
